# -*- coding: utf-8 -*-
"""Autoencoder_denoising.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19n09yR3WRhFIAx_nRcaRdxt84QleXFDn
"""

import os

!ls '/content/drive/My Drive'

!unzip '/content/drive/My Drive/denoising-dirty-documents.zip'

!unzip 'train.zip'

!unzip 'train_cleaned.zip'

!ls

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from sklearn.model_selection import train_test_split

import keras
from keras import backend as K
from keras.layers import *
from keras.utils import np_utils
from keras import regularizers
from keras.regularizers import l2
from keras.models import Sequential,Model
from keras.callbacks import ModelCheckpoint
from sklearn.model_selection import train_test_split

print(len(os.listdir('train')))
print(len(os.listdir('train_cleaned')))

plt.figure(figsize=(15,7))
plt.subplot(1,2,1)
img=cv2.imread('train/'+os.listdir('train')[0])
plt.imshow(img)
plt.title('a random train image')
plt.subplot(1,2,2)
img1=cv2.imread('train_cleaned/'+os.listdir('train_cleaned')[0])
plt.imshow(img1)
plt.title('and it''s cleaned version')

img.shape

from keras.preprocessing.image import load_img, array_to_img, img_to_array
X=[]
for i in range(len(os.listdir('train'))):
  img=load_img('train/'+os.listdir('train')[i],color_mode = "grayscale",target_size=(420,540))
  img=img_to_array(img)
  img=img.astype('float32')/255
  #img=cv2.resize(img,(420,540),interpolation = cv2.INTER_AREA)
  X.append(img)
Y=[]
for i in range(len(os.listdir('train_cleaned'))):
  img=load_img('train_cleaned/'+os.listdir('train_cleaned')[i],color_mode = "grayscale",target_size=(420,540))
  img=img_to_array(img)
  img=img.astype('float32')/255
  #img=cv2.resize(img,(420,540),interpolation = cv2.INTER_AREA)
  Y.append(img)

input_img = Input(shape=(420,540,1), name='image_input')
    
#enoder 
x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1')(input_img)
x = MaxPooling2D((2,2), padding='same', name='pool1')(x)

#decoder
x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3')(x)
x = UpSampling2D((2,2), name='upsample1')(x)
x = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='Conv5')(x)

#model
autoencoder = Model(inputs=input_img, outputs=x)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

autoencoder.summary()

X=np.array(X)
Y=np.array(Y)
X.shape=(144,420,540,1)
Y.shape=(144,420,540,1)
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=21)

Y.shape

X_train.shape

history=autoencoder.fit(X_train, Y_train,
                epochs=100,
                batch_size=8,
                validation_data=(X_test, Y_test))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.figure(figsize=(15,7))
plt.subplot(1,3,1)
xx=X[1]
xx.shape=(420,540)
plt.imshow(xx,cmap='gray')
plt.title("Original")
plt.subplot(1,3,2)
yy=Y[1]
yy.shape=(420,540)
plt.imshow(yy,cmap='gray')
plt.title('Cleaned')
plt.subplot(1,3,3)
xx.shape=(1,420,540,1)
pred=autoencoder.predict(xx)
pred.shape=(420,540)
plt.imshow(pred,cmap='gray')
plt.title('Model Cleaned')

input_img = Input(shape=(420,540,1), name='image_input')
    
x1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)
x1 = MaxPool2D( (2, 2), padding='same')(x1)
x2 = Conv2D(32, (3, 3), activation='relu', padding='same')(x1)
x2 = MaxPool2D( (2, 2), padding='same')(x2)
x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(x2)
encoded    = MaxPool2D( (2, 2), padding='same')(x3)

# decoding architecture
x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
x3 = UpSampling2D((2, 2))(x3)
x2 = Conv2D(32, (3, 3), activation='relu', padding='same')(x3)
x2 = UpSampling2D((2, 2))(x2)
x1 = Conv2D(64, (3, 3), activation='relu')(x2)
x1 = UpSampling2D((2, 2))(x1)
decoded   = Conv2D(1, (3, 3), padding='same')(x1)


model = Model(input_img, decoded)

model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy')
history_new=model.fit(X_train, Y_train,
                epochs=100,
                batch_size=8,
                validation_data=(X_test, Y_test))

plt.plot(history_new.history['loss'])
plt.plot(history_new.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.figure(figsize=(15,7))
plt.subplot(1,3,1)
xx=X[1]
xx.shape=(420,540)
plt.imshow(xx,cmap='gray')
plt.title("Original")
plt.subplot(1,3,2)
yy=Y[1]
yy.shape=(420,540)
plt.imshow(yy,cmap='gray')
plt.title('Cleaned')
plt.subplot(1,3,3)
xx.shape=(1,420,540,1)
pred=model.predict(xx)
pred.shape=(420,540)
plt.imshow(pred,cmap='gray')
plt.title('Deeper Model Cleaned')

# CONCLUSIONS :: 0.909 && 0.202 last validation accuracy for the shallower and the deeper model.